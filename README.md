# ğŸ§  GenAI Playground

A comprehensive LLM framework with dynamic parameter configuration and task orchestration.

## ğŸ“ Project Structure

```
llm/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ server.py                       # Server runner with ngrok support
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parameters.json             # Parameter definitions
â”‚   â”œâ”€â”€ task_overrides.json         # Task-specific overrides
â”‚   â”œâ”€â”€ models.py                   # Model configurations
â”‚   â””â”€â”€ tasks.py                    # Task configurations
â”œâ”€â”€ core/                           # Core functionality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task_orchestrator.py        # Task execution orchestration
â”‚   â””â”€â”€ vectorstore.py              # Vector store management
â”œâ”€â”€ components/                     # Model components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ encoder.py                  # Encoder models
â”‚   â”œâ”€â”€ decoder.py                  # Decoder models
â”‚   â”œâ”€â”€ encoder_decoder.py          # Encoder-decoder models
â”‚   â””â”€â”€ preprocessor.py             # Text preprocessing
â””â”€â”€ utils/                          # Utilities
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ core_utils.py               # Core utility functions
    â””â”€â”€ ui_utils.py                 # UI helper functions
```

## ğŸš€ Quick Start

### Run the Application
```bash
# Start the Streamlit app
python server.py

# Or run directly
streamlit run app.py
```

### Development
```bash
# Install dependencies
pip install streamlit pyngrok langchain transformers torch

# Run tests
python -c "import config.tasks; print('Configuration loaded successfully')"
```

## ğŸ”§ Configuration

### Parameters (`config/parameters.json`)
- **Encoding parameters**: Pooling strategies, normalization, device settings
- **Decoding parameters**: Temperature, top-k, max length settings
- **Preprocessing parameters**: Text splitting, chunking configurations

### Task Overrides (`config/task_overrides.json`)
- **Ideal values**: Task-specific recommended parameter values
- **Reasoning**: Explanations for why certain values work best

### Models (`config/models.py`)
- **Encoder models**: Sentence transformers, BERT variants
- **Decoder models**: GPT variants, text generation models
- **Encoder-decoder models**: T5, BART, summarization models

## ğŸ¯ Supported Tasks

1. **RAG-based QA**: Document-based question answering
2. **Normal QA**: Direct question answering
3. **Summarization**: Text summarization

## ğŸ“Š Features

- âœ… **Dynamic parameter configuration** from JSON files
- âœ… **Task-specific ideal values** with explanations
- âœ… **Multiple model types** (encoder, decoder, encoder-decoder)
- âœ… **Real-time parameter widgets** (dropdowns, sliders, checkboxes)
- âœ… **Ngrok tunneling** for easy sharing
- âœ… **Memory management** for GPU optimization

## ğŸ”„ Recent Changes

- **Restructured codebase** for better organization
- **Renamed files** for clarity and consistency
- **Separated utilities** into core and UI functions
- **Enhanced JSON integration** with dynamic parameter loading 